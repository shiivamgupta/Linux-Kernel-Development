1. Chapter 12 looks at how the kernel manages physical memory; in addition to managing its own memory, the kernel also has to manage the memory of user-space processes. This memory is called the process address space. An individual process's view of memory is as if it alone has full access to the system's physical memory. More important, the address space of a single process can be much larger than physical memory.

2. Address spaces:
The process address space consists of the virtual memory addressable by a process and the addresses within the virtual memory that the process is allowed to use. Each process is given a flat 32- or 64-bit address space. (The term flat denotes that the address space exists in a single range. Some operating systems provide a segmented address space, with addresses existing not in a single linear range, but instead in multiple segments. Modern virtual memory operating systems generally have a flat memory mode and not a segmented one.) 
On 32-bit architecture, although a process can address up to 4GB of memory, it doesn't have permission to access all of it. The intervals of memory addresses that the process has permission to access are called "memory areas". The process can dynamically add and remove memory areas to its address space. 
Memory areas do not overlap, a valid address in the process address space exists in exactly one area.

3. The memory descriptor:
The kernel represents a process address space using a data structure called memory descriptor, of the type struct mm_struct, which is defined in <linux/mm_types.h>:
============================================================
struct mm_struct {
	struct vm_area_struct* mmap;                    /* list of memory areas */
	struct rb_root mm_rb;                           /* root node of the red-black tree of VMAs */
	struct vm_area_struct* mmap_cache;              /* last used memory area */
	unsigned long free_area_cache;                  /* 1st address space hole */
	pgd_t* pgd;                                     /* page global directory */
	atomic_t mm_users;                              /* see below */
	atomic_t mm_count;                              /* see below */
	int map_count;                                  /* number of memory areas */
	struct rw_semaphore mmap_sem;                   /* rw-semaphore to protect memory descriptor */
	spinlock_t page_table_lock;                     /* spinlock to protect page table (PGD) */
	struct list_head mmlist;                        /* all mm_structs are in the doubly linked list, they're globally strung together off init_mm.mmlist, 
                                                       and are protected by mmlist_lock */
	unsigned long start_code;                       /* start address of code */
	unsigned long end_code;
	unsigned long start_data;
	unsigned long end_data;
	unsigned long start_brk;
	unsigned long brk;
	unsigned long start_stack;
	unsigned long arg_start;
	unsigned long arg_end;
	unsigned long env_start;
	unsigned long env_end;                          /* end address of environment argument */
	unsigned long rss;                              /* page allocated? */
	unsigned long total_vm;                         /* total number of pages */
	unsigned long locked_vm;                        /* number of locked pages */
	unsigned long saved_auxv[AT_VECTOR_SIZE];       /* ? */
	cpumask_t cpu_vm_mask;                          /* lazy TLB switch mask */
	mm_context_t context;                           /* arch-specific data */
	unsigned long flags;                            /* status flags */
	int core_waiters;                               /* ? */
	struct core_state* core_state;                  /* core dump support */
	spinlock_t ioctx_lock;                          /* AIO I/O list lock */
	struct hlist_head ioctx_list;                   /* AIO I/O list */
};
============================================================
The mm_users field is the number of processes using this address space. The mm_count is the primary reference count for the mm_struct, which is always 1 as long as mm_users > 0. Only when mm_users reaches 0 (when all threads using an address space exit) is mm_count decremented, it means no remaining references to this mm_struct and it is freed.
mmap and mm_rb fields are different data structures that contain the same thing: all the memory areas in this address space. mmap stores them in a linked list, while mm_rb stores in a red-black tree. The kernel isn't duplicating the mm_struct structures, just the containing objects. Overlaying a linked list onto a tree, and using both to access the same set of data, is called threaded tree.
All of the mm_struct structures are strung together in a doubly linked list via mmlist field. The initial element in the list is the init_mm memory descriptor. The list is protected from concurrent access via the mmlist_lock, which is defined in kernel/fork.c

• Allocating a memory descriptor:
The memory descriptor associated with a given task is stored in the mm field of the task's task_struct structure. The copy_mm() function copies a parent's memory descriptor to its child during fork(). The mm_struct is allocated from the mm_cachep slab cache via allocate_mm() macro in kernel/fork.c. In the case that CLONE_VM is specified in clone(), allocate_mm() is not called, and the process's mm field is set to the memory descriptor of its parent's.

• Destroying a memory descriptor:
When the process associated with a specific address space exits, the exit_mm() is invoked, which is defined in kernel/exit.c. It calls mmput(), which decrements the memory descriptor's mm_users by 1. If mm_users reaches 0, mmdrop() is called to decrement the mm_count field. If that counter is finally 0, the free_mm() macro is invoked to return the mm_struct to the mm_cachep slab cache via kmem_cache_free(). 

• The mm_struct and kernel threads:
Kernel threads do not have a process address space and therefore do not have an associated memory descriptor. Thus, the mm field of a kernel thread's process descriptor is NULL. (This is the definition of kernel thread: process that doesn't have user context.) This lack of an address space is fine because kernel threads do not ever access any user-space memory. Because kernel threads do not have any pages in user-space, they do not deserve their own memory descriptor and page tables. However, kernel threads need some of the data such as the page tables to access kernel memory. So kernel threads use the memory descriptor of whatever task ran previously.
Whenever a process is scheduled, the process address space referenced by the process's mm field is loaded. The active_mm field in the process descriptor is then updated to refer to the new address space. When kernel threads are scheduled, the kernel notices that its mm field is NULL, so keeps the previous process's address space loaded. The kernel then updates the active_mm field of the kernel thread's process descriptor to refer to the previous process's memory descriptor. The kernel can then use the previous process's page tables as needed, because kernel threads do not access user-space memory, they make use of only the information in the address space pertaining to kernel memory, which is same for all processes.

4. Virtual memory areas:
struct vm_area_struct, defined in <linux/mm_types.h>, represents memory areas. In the linux kernel, memory areas are often called virtual memory areas (VMA). The vm_area_struct structure describes a single memory area over a contiguous interval in a given address space.
=======================================================
struct vm_area_struct{
	struct mm_struct* vm_mm;                       /* associated mm_struct */
	unsigned long vm_start;                        /* VMA start, inclusive */
	unsigned long vm_end;                          /* VMA end, exclusive */
	struct vm_area_struct* vm_next;                /* list of VMAs */
	pgprot_t vm_page_prot;                         /* access permission */
	unsigned long vm_flags;                        /* flags, see below */
	struct rb_node vm_rb;                          /* VMA's node in the tree */
	union{                                         /* links to address_space->i_mmap of i_mmap_nonlinear */
		struct{
			struct list_head list;
			void* parent;
			struct vm_area_struct* head;
		}vm_set;
		struct prio_tree_node prio_tree_node;
	}shared;
	struct list_head anon_vma_node;                /* anon_vma entry? */
	struct anon_vma* anon_vma;                     /* anonymous VMA object? */
	struct vm_operations_struct* vm_ops;           /* associated ops */
	unsigned long vm_pgoff;                        /* offset within vm_file, in PAGE_SIZE units */
	struct file* vm_file;                          /* mapped file, if any */
	void* vm_private_data;                         /* private data */
};
=======================================================
Intervals in different memory areas in the same address space cannot overlap.
• vm_flags:
The vm_flags field contains bit flags, defined in <linux/mm.h>. Unlike permissions associated with a specific physical page, the VMA flags specify behavior for the kernel, not the hardware. Furthermore, vm_flags contains information that relates to each page in the memory area, or the memory area as a whole, and not specific individual page.
VM_READ, VM_WRITE, VM_EXEC: pages can be read from, written, executed. // This specifies the permission for all the pages in this area.
VM_SHARED: Pages are shared. // If this flag is set, this area is shared by multiple processes, then the mapping is called shared mapping; otherwise this area is owned by one single process, and it is called private mapping.
VM_MAYREAD, VM_MAYWRITE, VM_MAYEXEC, VM_MAYSHARE: The VM_READ, VM_WRITE, VM_EXEC, VM_SHARE flag can be set.
VM_GROWUP, VM_GROWDOWN: The area can grow upward/downward.
VM_SHM: The area is used for shared memory.
VM_DENYWRITE: The area maps an unwritable file.
VM_EXECUTABLE: The area maps an executable file.
VM_LOCKED: The pages in this area are locked.
VM_IO: The area maps a device's I/O space. // This flag specifies that this memory area is a mapping of a device's I/O space. This field is typically set by device drivers when mmap() is called on their I/O space. It specifies that the memory area must not be included in any process's core dump.
VM_SEQ_READ: The pages seem to be accessed sequentially. // Provide a hint to kernel that the application is performing sequential reads in this mapping. So the kernel can then opt to increase the read-ahead performed on the backing file.
VM_RAND_READ: The pages seem to be accessed randomly. // This flag specifies the opposite to the above flag: the application is performing relatively random reads in this mapping. So the kernel can opt to decrease or disable read-ahead on the backing file. These two flags are set via madvice() syscall.
VM_DONTCOPY: This area must not be copied on fork().
VM_DONTEXPAND: This area cannot grow via mremap().
VM_RESERVED: This area must not be swapped out. // It's also used by device driver mappings.
VM_ACCOUNT: This area is an accounted VM object.
VM_HUGETLB: This area uses hugetlb pages.
VM_NONLINEAR: This area is a nonlinear mapping.

• VMA operations:
The vm_ops field in the vm_area_struct structure points to the table of operations associated with a given memory area, like the VFS way. Defined in <linux/mm.h>:
============================================================================
struct vm_operations_struct{
	void (*open)(struct vm_area_struct*); /* Invoked whenever a new reference is made to the given memory area, like when a process forks. The one exception happens when the VMA is first created by mmap, in this case the driver's mmap method is called. */
	void (*close)(struct vm_area_struct*); /* Invoked when the given memory area is removed from an address space. Note that there is no usage count associated with VMAs; the area is opened and closed exactly once by each process that uses it. */
	int (*fault)(struct vm_area_struct*, struct vm_fault*); /* Invoked by the page fault handler when a page that is not present in physical memory is accessed */
	int (*page_mkwrite)(struct vm_area_struct* vma, struct vm_fault* vmf); /* Invoked by the page fault handler when a page that was read-only is being made writable */
	int (*access)(struct vm_area_struct*, unsigned long, void*, int, int); /* Invoked by access_process_vm() when get_user_pages() fails. */
};
============================================================================

• Lists and trees of memory areas:
As discussed before, memory areas are accessed via both the mmap and mm_rb fields of the memory descriptor. In fact, they both contain pointers to the same vm_area_struct structures, just represented in different ways.
The former representation mmap, using a single linked list to link all the memory area objects. Each vm_area_struct is linked into the list via its vm_next field. The areas are sorted by ascending address. The first item in the list is mmap points to, the last item is NULL.
The latter representation mm_rb, links all the memory area objects in a red-black tree.

• Memory areas in real life:
See the contents in /proc/<pid>/maps, which lists the memory areas in this process's address space. The format is of the form: 
"start-end    permission    offset    major:minor    inode    file"
Note the memory areas without a mapped file on device 00:00 and inode 0. This is the zero page, which is a mapping that consists of all zeros. Each of the memory areas associated with the process corresponds to a vm_area_struct structure.

5. Manipulating memory areas:
The kernel often has to perform operations on a memory area, such as whether a given address exists in a given VMA. The functions are all declared in <linux/mm.h>.
• find_vma():
struct vm_area_struct* find_vma(struct mm_struct* mm, unsigned long addr);  // defined in mm/mmap.c
This function searches the given address space for the first memory area whose vm_end > addr. In other words, this function finds the first memory area that contains addr or begins at an address greater than addr. (Returns NULL if no such memory area exists.) Note that because the returned VMA may start at an address greater than the given address addr, so it doesn't mean addr lies inside the returned VMA (if returned_VMA != NULL) 
The result of find_vma() is cached in the mmap_cache field of the memory descriptor. (This cache hit ratio is about 30% ~ 40% in practice.) If the given address is not in the cache, you must search the memory areas associated with this memory descriptor (in the red-black tree).
===========================================================================
struct vm_area_struct* find_vma(struct mm_struct* mm, unsigned long addr)
{
	struct vm_area_struct* vma = NULL;
	if(mm)
	{
		vma = mm->mmap_cache;
		if(!(vma && vma->vm_end > addr && vma->vm_start <= addr))
		{
			struct rb_node* rb_node;
			rb_node = mm->mm_rb.rb_node;
			vma = NULL;
			while(rb_node)
			{
				struct vm_area_struct* vma_tmp;
				vma_tmp = rb_entry(rb_node, struct vm_area_struct, vm_rb);
				if(vma_tmp->vm_end > addr)
				{
					vma = vma_tmp;
					if(vma_tmp->vm_start <= addr)
						break;
					rb_node = rb_node->rb_left;
				}
				else
				{
					rb_node = rb_node->rb_right;
				}
			}
		}
		if(vma)
			mm->mmap_cache = vma;
	}
	return vma;
}
===========================================================================
The initial check of mmap_cache tests whether the cached VMA contains the desired address. Note that simply checking whether the VMA's vm_end field is larger than addr would not ensure that this is the first such VMA that is larger than addr. Thus for the cache to be useful here, the given addr must lies inside the VMA - and this is just the scenario that consecutive operations on the same VMA would occur.
If the cache doesn't contain the desired VMA, the function must search the memory areas red-black tree. The functions terminates as soon as a VMA is found that contains the given address. If such a VMA is not found, the function continues traversing the tree and returns the first VMA it found that starts after addr. If no VMA is ever found, NULL is returned.

• find_vma_prev():
struct vm_area_struct* find_vma_prev(struct mm_struct* mm, unsigned long addr, struct vm_area_struct** pprev);
Defined in mm/mmap.c, this function works the same as find_vma(), but it also returns the last VMA before addr, which pointer is stored in pprev.

• find_vma_intersection():
Defined in <linux/mm.h> because it is an inline function, find_vma_intersection() returns the first vma that overlaps a given address interval.
======================================
static inline struct vm_area_struct* find_vma_intersection(struct mm_struct* mm, 
		unslgned long start_addr, unsigned long end_addr)
{
	struct vm_area_struct* vma;
	vma = find_vma(mm, start_addr);
	if(vma && end_addr <= vma->vm_start)
		vma = NULL;
	return vma;
}
Draw several diagrams so you could understand why it could be implemented in such a simple way.

6. mmap() and do_mmap(): creating an address interval (memory area)
The do_mmap() is used by the kernel to create a new linear address interval to a process's address space. If the created address interval is adjacent to an existing address interval, and if they share the same permissions, the two intervals are merged into one. If this merge is impossible, a new VMA is created.
	#include <linux/mm.h>:
	unsigned long do_mmap(struct file* file, unsigned long addr, unsigned long len, unsigned long prot, unsigned long flag, unsigned long offset);
This function maps the file specified by @file at @offset for length @len. The file parameter can be NULL and the offset can be zero, in which case, the mapping will not be backed by a file (anonymous mapping). If a file and an offset are provided, the mapping is called a file-backed mapping.
The addr parameter optionally specifies the initial address from which to start the search for a free interval.
The prot parameter specifies the access permission for pages in the memory area. Usual flags include: PROT_READ, PROT_WRITE, PROT_EXEC, PROT_NONE. See p318 for more details.
The flag parameter specifies the type of the mapping, and change the behavior of the mapping. They are defined in <asm/mman.h>

If any of the parameters are invalid, do_mmap() returns a negative value. Otherwise, the function returns the initial address of the newly created address interval.
The do_mmap() is exported to user-space via the mmap() syacall.

• munmap() and do_munmap(): removing an address interval
Declared in <linux/mm.h>:
int do_munmap(struct mm_struct* mm, unsigned long start, size_t len);
on success, zero is returned, otherwise a negative error code is returned.

The munmap() syscall is exported to user-space to enable processes to remove address intervals from their address space:
int munmap(void* start, size_t length);
The syscall is defined in mm/mmap.c and acts as a simple wrapper to do_munmap():
============================================================
asmlinkage long sys_munmap(unsigned long addr, size_t len)
{
	int ret;
	struct mm_struct* mm;
	mm = current->mm;
	down_write(&mm->mmap_sem);
	ret = do_munmap(mm, addr, len);
	up_write(&mm->mmap_sem);
	return ret;
}
============================================================

7. Page tables:
In linux, page tables consist of three levels, even on architectures that do not support three levels in hardware.
The top level page table is the page global directory (PGD), of the type pgd_t. On most architectures the pgd_t type is unsigned long. 
The second level page table is the page middle directory (PMD), of the type pmd_t.
The final level page table is simply called page table and consists of page table entries, of the type pte_t.
Each process has its own page tables. The pgd field of the memory descriptor points to the process's page global directory. Manipulating and traversing page tables requires the page_table_lock, which is located inside the associated memory descriptor.
Page table data structures are quite architecture-dependent and thus are defined in <asm/page.h>.
